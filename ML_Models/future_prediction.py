# -*- coding: utf-8 -*-
"""future_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l3UPIsDtnxF7sWK5ue1Oo_o20Cw4JlSZ
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
file_path = '/content/drive/My Drive/data/Future.csv'
df = pd.read_csv(file_path)
print(df.head())

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from statsmodels.tsa.arima.model import ARIMA

!pip install xgboost scikit-learn pandas numpy matplotlib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import r2_score, mean_absolute_error
import matplotlib.pyplot as plt

print("Dataset shape:", df.shape)
df.head()

"""Step 3: Data Cleaning & Preprocessing"""

# Convert list-type columns (Recycling, Cooking_With) to strings
df['Recycling'] = df['Recycling'].astype(str)
df['Cooking_With'] = df['Cooking_With'].astype(str)

# Drop rows with missing target
df = df.dropna(subset=['CarbonEmission'])

# Separate features and target
X = df.drop('CarbonEmission', axis=1)
y = df['CarbonEmission']

# Identify categorical and numerical columns
cat_cols = [
    'Body Type', 'Sex', 'Diet', 'How Often Shower',
    'Heating Energy Source', 'Transport', 'Vehicle Type',
    'Social Activity', 'Frequency of Traveling by Air',
    'Waste Bag Size', 'Energy efficiency', 'Recycling', 'Cooking_With'
]

num_cols = [
    'Monthly Grocery Bill', 'Vehicle Monthly Distance Km',
    'Waste Bag Weekly Count', 'How Long TV PC Daily Hour',
    'How Many New Clothes Monthly', 'How Long Internet Daily Hour'
]

# Fill missing numeric with median, categorical with mode
for col in num_cols:
    X[col] = X[col].fillna(X[col].median())

for col in cat_cols:
    X[col] = X[col].fillna(X[col].mode()[0])

"""‚öôÔ∏è Step 4: One-Hot Encode Categorical Features"""

encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
X_encoded = encoder.fit_transform(X[cat_cols])

# Combine encoded categorical and numeric columns
X_num = X[num_cols].reset_index(drop=True)
X_final = np.hstack((X_encoded, X_num))

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(
    X_final, y, test_size=0.2, random_state=42
)

print("Training samples:", X_train.shape[0])
print("Testing samples:", X_test.shape[0])

"""Step 5: Random Forest Model"""

rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)

print("üå≥ Random Forest Performance:")
print("R¬≤ Score:", r2_score(y_test, y_pred_rf))
print("MAE:", mean_absolute_error(y_test, y_pred_rf))

plt.figure(figsize=(6,4))
plt.scatter(y_test, y_pred_rf, alpha=0.6)
plt.xlabel("Actual Emission")
plt.ylabel("Predicted Emission")
plt.title("Random Forest Prediction vs Actual")
plt.show()

"""XGBoost Model"""

xgb = XGBRegressor(
    n_estimators=300, learning_rate=0.05, max_depth=6, random_state=42
)
xgb.fit(X_train, y_train)

y_pred_xgb = xgb.predict(X_test)

print("‚ö° XGBoost Performance:")
print("R¬≤ Score:", r2_score(y_test, y_pred_xgb))
print("MAE:", mean_absolute_error(y_test, y_pred_xgb))

plt.figure(figsize=(6,4))
plt.scatter(y_test, y_pred_xgb, color='green', alpha=0.6)
plt.xlabel("Actual Emission")
plt.ylabel("Predicted Emission")
plt.title("XGBoost Prediction vs Actual")
plt.show()

"""Simulate Lifestyle Change"""

# Pick a sample user
user = X.iloc[2].copy()

print("Before change:")
print(user)

# Simulate eco-friendly lifestyle change
user['Diet'] = 'vegetarian'
user['Heating Energy Source'] = 'solar'
user['Transport'] = 'walk/bicycle'
user['Energy efficiency'] = 'Yes'
user['Recycling'] = "['Paper', 'Plastic', 'Glass', 'Metal']"

# Encode and predict again
user_df = pd.DataFrame([user])
user_enc = encoder.transform(user_df[cat_cols])
user_num = user_df[num_cols].reset_index(drop=True)
user_final = np.hstack((user_enc, user_num))

# Predict new emission with Random Forest
pred_emission = rf.predict(user_final)[0]
print(f"\nPredicted CarbonEmission after lifestyle change: {pred_emission:.2f} kg CO‚ÇÇ")

import pandas as pd
from statsmodels.tsa.arima.model import ARIMA
import matplotlib.pyplot as plt
import numpy as np

# Create a synthetic date column
# Pretend each record is one sequential month
# Reducing the number of periods to avoid OutOfBoundsDatetime error
df_time = pd.DataFrame({
    'Date': pd.date_range(start='2022-01-01', periods=100, freq='MS'), # Reduced periods to 100
    'CarbonEmission': df['CarbonEmission'].head(100).values # Using the first 100 carbon emission values
})

# Group (if needed) and make sure it's a proper time series
ts = df_time.groupby('Date')['CarbonEmission'].mean().asfreq('MS').interpolate()

# Fit ARIMA model
model = ARIMA(ts, order=(2,1,2)).fit()
forecast = model.forecast(steps=12)

# Plot historical + forecast
plt.figure(figsize=(8,4))
plt.plot(ts, label='Historical')
plt.plot(forecast, label='Forecast', color='red')
plt.title('Future Carbon Footprint Forecast (ARIMA)')
plt.legend()
plt.show()

"""predictive

Data Cleaning and Feature Encoding
"""

# Convert list-type columns to string
df['Recycling'] = df['Recycling'].astype(str)
df['Cooking_With'] = df['Cooking_With'].astype(str)

# Fill missing values
df = df.fillna({
    'Vehicle Type': 'none',
    'Heating Energy Source': 'none',
    'Transport': 'none',
    'Diet': 'omnivore',
    'Energy efficiency': 'No'
})

# Separate features & target
X = df.drop('CarbonEmission', axis=1)
y = df['CarbonEmission']

# Define categorical & numeric columns
cat_cols = [
    'Body Type', 'Sex', 'Diet', 'How Often Shower',
    'Heating Energy Source', 'Transport', 'Vehicle Type',
    'Social Activity', 'Frequency of Traveling by Air',
    'Waste Bag Size', 'Energy efficiency', 'Recycling', 'Cooking_With'
]

num_cols = [
    'Monthly Grocery Bill', 'Vehicle Monthly Distance Km',
    'Waste Bag Weekly Count', 'How Long TV PC Daily Hour',
    'How Many New Clothes Monthly', 'How Long Internet Daily Hour'
]

# Encode categorical features
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
X_encoded = encoder.fit_transform(X[cat_cols])

# Combine numeric + encoded
X_num = X[num_cols].reset_index(drop=True)
X_final = np.hstack((X_encoded, X_num))

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)

# Train Random Forest
rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

# Train XGBoost
xgb = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=6)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)

# Evaluate
print("üå≥ Random Forest R¬≤:", r2_score(y_test, y_pred_rf))
print("üå≥ MAE:", mean_absolute_error(y_test, y_pred_rf))
print("‚ö° XGBoost R¬≤:", r2_score(y_test, y_pred_xgb))
print("‚ö° MAE:", mean_absolute_error(y_test, y_pred_xgb))

# Select one user‚Äôs record
user = X.iloc[2].copy()  # Change index as needed

print("User baseline details:\n")
print(user)

# --- 1Ô∏è‚É£ Predict current (before change) emission ---
user_df = pd.DataFrame([user])
user_enc = encoder.transform(user_df[cat_cols])
user_num = user_df[num_cols].reset_index(drop=True)
user_final = np.hstack((user_enc, user_num))
baseline_emission = rf.predict(user_final)[0]

print(f"\nüåç Carbon Emission BEFORE lifestyle change: {baseline_emission:.2f} kg CO‚ÇÇ")

# --- 2Ô∏è‚É£ Apply lifestyle improvements ---
user_changed = user.copy()
user_changed['Diet'] = 'vegetarian'
user_changed['Heating Energy Source'] = 'solar'
user_changed['Transport'] = 'walk/bicycle'
user_changed['Energy efficiency'] = 'Yes'
user_changed['Recycling'] = "['Paper','Plastic','Glass','Metal']"

# --- 3Ô∏è‚É£ Predict new (after change) emission ---
user_df2 = pd.DataFrame([user_changed])
user_enc2 = encoder.transform(user_df2[cat_cols])
user_num2 = user_df2[num_cols].reset_index(drop=True)
user_final2 = np.hstack((user_enc2, user_num2))
new_emission = rf.predict(user_final2)[0]

# --- 4Ô∏è‚É£ Calculate CO‚ÇÇ saved ---
saved = baseline_emission - new_emission
percent = (saved / baseline_emission) * 100

print(f"üåø Carbon Emission AFTER lifestyle change: {new_emission:.2f} kg CO‚ÇÇ")
print(f"‚úÖ Saved CO‚ÇÇ: {saved:.2f} kg ({percent:.1f}% reduction)")

plt.figure(figsize=(5,4))
plt.bar(['Before Change', 'After Change'], [baseline_emission, new_emission],
        color=['red', 'green'], alpha=0.7)
plt.title("Carbon Footprint Before vs After Lifestyle Change")
plt.ylabel("CarbonEmission (kg CO‚ÇÇ)")
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)

xgb = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=6, random_state=42)
xgb.fit(X_train, y_train)

print("‚úÖ Predictive model trained successfully!")

# Select one user from dataset
user = X.iloc[2].copy()

# Scenario A ‚Äî BEFORE lifestyle change
user_before = user.copy()

# Scenario B ‚Äî AFTER lifestyle change
user_after = user.copy()
user_after['Diet'] = 'vegetarian'
user_after['Heating Energy Source'] = 'solar'
user_after['Transport'] = 'walk/bicycle'
user_after['Energy efficiency'] = 'Yes'
user_after['Recycling'] = "['Paper','Plastic','Glass','Metal']"

# Generate 30 future days
future_days = pd.date_range(start='2025-10-15', periods=30)

# Initialize lists
pred_before, pred_after = [], []

for day in future_days:
    # Encode before-change user
    user_df_before = pd.DataFrame([user_before])
    enc_before = encoder.transform(user_df_before[cat_cols])
    num_before = user_df_before[num_cols].reset_index(drop=True)
    user_final_before = np.hstack((enc_before, num_before))

    # Predict emission before lifestyle change
    emission_before = xgb.predict(user_final_before)[0]
    pred_before.append(emission_before)

    # Simulate 1% monthly improvement in eco habits
    user_after['Monthly Grocery Bill'] *= 0.999
    user_after['Vehicle Monthly Distance Km'] *= 0.98

    user_df_after = pd.DataFrame([user_after])
    enc_after = encoder.transform(user_df_after[cat_cols])
    num_after = user_df_after[num_cols].reset_index(drop=True)
    user_final_after = np.hstack((enc_after, num_after))

    emission_after = xgb.predict(user_final_after)[0]
    pred_after.append(emission_after)

plt.figure(figsize=(10,5))
plt.plot(future_days, pred_before, color='red', label='Before Lifestyle Change')
plt.plot(future_days, pred_after, color='green', label='After Lifestyle Change')
plt.title("Predicted Carbon Footprint for Next 30 Days")
plt.xlabel("Date")
plt.ylabel("Predicted CarbonEmission (kg CO‚ÇÇ)")
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.show()

# Display stats
avg_before = np.mean(pred_before)
avg_after = np.mean(pred_after)
saved = avg_before - avg_after
percent_saved = (saved / avg_before) * 100

print(f"\nüìÖ Average Daily Emission (Before): {avg_before:.2f} kg CO‚ÇÇ")
print(f"üåø Average Daily Emission (After): {avg_after:.2f} kg CO‚ÇÇ")
print(f"‚úÖ Estimated CO‚ÇÇ Reduction: {saved:.2f} kg/day ({percent_saved:.1f}% decrease)")

